# -*- coding: utf-8 -*-
"""WSN_K-means.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17oo0r9CQ4wS8XQt8BGbKtBRAo9KiausV
"""

from google.colab import drive
drive.mount('/content/drive')

"""#Import Packages"""

# Commented out IPython magic to ensure Python compatibility.
# Importing the neccessary modules for data manipulation and visual representation

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib as matplot
import seaborn as sns
# %matplotlib inline

# import plotly.plotly as py

"""#Read the Data"""

df = pd.read_csv (r'/content/drive/MyDrive/beach-water-quality-automated-sensors.csv')
# Examining the dataset
print ("This is Beach water quality sensors total row and column   : " + str(len(df)))
df.head()

"""# Feature Engineering"""

df_column_headers= list(df)

df["Beach Name"] = "("+df["Wave Period"].map(str)+","+df["Wave Height"].map(str)+")"

df['frequency'] = df['Beach Name'].map(df['Beach Name'].value_counts())

df.sort_values(by=['frequency'], ascending=False).head(3)

"""#Descriptive Statistics"""

for column1 in df_column_headers:
    print("Description for Feature:  ",column1)
    print(df[str(column1)].describe())
    print("\n")

"""#Info() Analysis"""

# Checking the type of our features. 
df.dtypes

#How many attributes are there in the dataset
df.shape

"""#Exploring the Data"""

df = pd.read_csv (r'/content/drive/MyDrive/beach-water-quality-automated-sensors.csv')
d=pd.DataFrame(df)
print(d)

"""#Visualizations"""

# resizing the plot size
plt.figure(figsize=(15,8))
# Plotting the countplot from seaborn library
ax=sns.countplot(x="Beach Name",data=df,hue="Beach Name")

# Setting the title, increasing font size
ax.axes.set_title("Beach-water-quality-automated-sensors",fontsize=20)
# Setting the x and y label i.e name along axis, increasing font size
ax.set_xlabel("Beach Name",fontsize=15)
ax.set_ylabel("Battery Life",fontsize=15)
# Increasing the fontsize of values of each label
ax.tick_params(labelsize=12)

plt.show

"""#K-Means Implementation with Data quality check"""

df.isnull().any()

df.info()

df.dropna(inplace=True)

df.isnull().any()

df.head()

df['Beach Name']

df.drop(['Measurement ID','Measurement Timestamp'],axis=1,inplace=True)

df.head()

X = df.iloc[:,[1,2,3,4,5,6]]

y=df.iloc[:,0].values
y

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.cluster import KMeans

"""#Parameter:- K-value and SSE"""

SSE = []
for cluster in range(1,20):
    kmeans = KMeans(n_jobs = -1, n_clusters = cluster, init='k-means++')
    kmeans.fit(X_scaled)
    SSE.append(kmeans.inertia_)

# converting the results into a dataframe and plotting them
frame = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})
plt.figure(figsize=(12,6))
plt.plot(frame['Cluster'], frame['SSE'], marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')

kmeans = KMeans(n_jobs = -1, n_clusters = 5, init='k-means++')
pred = kmeans.fit_predict(X_scaled)

pred
len(pred)

plt.figure(figsize=(25,10))
plt.scatter(X_scaled[:,0],X_scaled[:,1],c=pred,cmap='rainbow')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], marker='*',s = 250, c = 'yellow', label = 'Centroids')
plt.title('K-Means clustering results (n_clusters=5)', fontsize=14)
plt.xlabel('Clustering on Numeric Data',fontsize=14)
plt.legend()

frame = pd.DataFrame(X_scaled)
frame['cluster'] = pred
frame['cluster'].value_counts()

kmeans = KMeans(n_clusters = 5, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)
y_kmeans = kmeans.fit_predict(X_scaled)
y_kmeans

"""Conversion from 1-Dimension to 2-Dimension array"""

pred1=pred
len(pred1)

#Conversion of 1D array - 2D array..
def show_array(y):
  print('array: \n', y)
  print('array.ndim:', y.ndim)
  print('array.shape:', y.shape)

from numpy import array, newaxis, expand_dims
pred1 = array(X)
show_array(pred1)

"""#Compute the Parameters
#Davies-Bouldin score
"""

#Computes the Davies-Bouldin score.
#The score is defined as the average similarity measure of each cluster with its most similar cluster, where similarity is the ratio of within-cluster distances to between-cluster distances. 
import sklearn
from sklearn.metrics import *
sklearn.metrics.davies_bouldin_score(pred1,y_kmeans*100)

"""#Homogenity_Score"""

#each cluster contains only members of a single class (range 0 - 1)
from sklearn import metrics
metrics.homogeneity_score(pred,y_kmeans)

"""#Silhouette_Analysis"""

silhouette_vals = silhouette_samples(pred1,y_kmeans)

metrics.silhouette_score(pred1,y_kmeans, metric='euclidean')

# Silhouette plot
#y_ticks = []
for i, k in enumerate([5]):
  fig, (ax1, ax2) = plt.subplots(1,2)
  fig.set_size_inches(16, 8)
y_lower, y_upper = 0, 0
for i, cluster in enumerate(np.unique(pred)):
    cluster_silhouette_vals = silhouette_vals[pred == cluster]
    cluster_silhouette_vals.sort()
    y_upper += len(cluster_silhouette_vals)
    ax1.barh(range(y_lower, y_upper), cluster_silhouette_vals, edgecolor='none', height=1)
    ax1.text(-0.03, (y_lower + y_upper) / 2, str(i + 1))
    y_lower += len(cluster_silhouette_vals)
       # Get the average silhouette score and plot it
    avg_score = np.mean(silhouette_vals)
    ax1.axvline(avg_score, linestyle='--', linewidth=2, color='green')
    ax1.set_yticks([])
    ax1.set_xlim([-0.1, 1])
    ax1.set_xlabel('Silhouette coefficient values')
    ax1.set_ylabel('Cluster labels')
    ax1.set_title('Silhouette plot for the various clusters', y=1.02);
     # Scatter plot of data colored with labels
    ax2.scatter(X_scaled[:, 0], X_scaled[:, 1], c=pred)
    ax2.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='*', c='r', s=250)
    ax2.set_xlim([0, 10])
    ax2.set_xlim([-5, 5])
    ax2.set_xlabel('Eruption time in mins')
    ax2.set_ylabel('Waiting time to next eruption')
    ax2.set_title('Visualization of clustered data', y=1.02)
    ax2.set_aspect('equal')
    plt.tight_layout()
    plt.suptitle(f'Silhouette analysis using k = {k}',
                 fontsize=16, fontweight='semibold', y=1.05);